{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# %cd /content/ease/ease\n",
    "\n",
    "## IMPORTS ##\n",
    "from essay_set import EssaySet\n",
    "\n",
    "from feature_extractor import FeatureExtractor\n",
    "from predictor_set import PredictorSet\n",
    "from predictor_extractor import PredictorExtractor\n",
    "from sklearn.svm import SVR\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "#from sklearn import svm, grid_search\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def Cmatrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = Cmatrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n",
      "Done1\n",
      "Done2\n",
      "features train [[4.460e+02 1.020e+02 2.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [8.320e+02 1.930e+02 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [9.140e+02 2.080e+02 3.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [5.170e+02 1.180e+02 2.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [7.920e+02 1.760e+02 2.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.188e+03 2.400e+02 4.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n",
      "Done3\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv('/home/mehar/github/ease/aes_data/essay7/fold_0/train.txt', sep='\\t')\n",
    "x = train_set.to_numpy()\n",
    "tester = x.tolist()\n",
    "print(len(tester))\n",
    "essaylist = []\n",
    "scorelist = []\n",
    "for i in range(0, len(tester)):\n",
    "    z = tester[i]\n",
    "    y = z[0].split(', ', 1)\n",
    "    #print(y)\n",
    "    scorelist.append(float(y[0]))\n",
    "    essaylist.append(y[1])\n",
    "\n",
    "train = EssaySet()\n",
    "print(\"Done1\")\n",
    "for i in range(0, len(essaylist)):\n",
    "    train.add_essay(essaylist[i], scorelist[i])\n",
    "\n",
    "print(\"Done2\")\n",
    "features=FeatureExtractor()\n",
    "features.initialize_dictionaries(train)\n",
    "X = features.gen_feats(train)\n",
    "print(\"features train\", X)\n",
    "print(\"Done3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_set = pd.read_csv('scores/test7.csv', encoding = 'utf=8')\n",
    "x_2 = test_score_set.to_numpy()\n",
    "tester_2 = x_2.tolist()\n",
    "\n",
    "test_scorelist = []\n",
    "\n",
    "for i in range(0, len(tester_2)):\n",
    "    z = tester_2[i]\n",
    "    test_scorelist.append(float(z[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 ['contractions_test_prompt7.csv', 'disfluency_7.csv', 'entities_beg_bound_7.csv', 'entities_beg_unbound_7.csv', 'entities_end_bound_7.csv', 'entities_end_unbound_7.csv', 'entities_mid_bound_7.csv', 'entities_mid_unbound_7.csv', 'incorrect_grammar_7.csv', 'para_P_7.csv', 'prompt 7 babel - Sheet1.csv', 'repeat_test_conc1.csv', 'repeat_test_conc2.csv', 'repeat_test_into1.csv', 'repeat_test_into2.csv', 'repeat_test_middle1.csv', 'repeat_test_middle2.csv', 'repeat_test_middle3.csv', 'songs_test_beg.csv', 'songs_test_end.csv', 'speeches_test_beg.csv', 'speeches_test_end.csv', 'test7.csv', 'uf_beg_bound_7.csv', 'uf_beg_unbound_7.csv', 'uf_end_bound_7.csv', 'uf_end_unbound_7.csv', 'uf_mid_bound_7.csv', 'uf_mid_unbound_7.csv', 'ut_beg_bound_7.csv', 'ut_beg_unbound_7.csv', 'ut_end_bound_7.csv', 'ut_end_unbound_7.csv', 'ut_mid_bound_7.csv', 'ut_mid_unbound_7.csv', 'wiki_beg_bound_7.csv', 'wiki_beg_unbound_7.csv', 'wiki_end_bound_7.csv', 'wiki_end_unbound_7.csv', 'wiki_mid_bound_7.csv', 'wiki_mid_unbound_7.csv', 'wiki_rel_beg_bound_7.csv', 'wiki_rel_beg_unbound_7.csv', 'wiki_rel_end_bound_7.csv', 'wiki_rel_end_unbound_7.csv', 'wiki_rel_mid_bound_7.csv', 'wiki_rel_mid_unbound_7.csv', 'wiki_topic_beg_bound_7.csv', 'wiki_topic_beg_unbound_7.csv', 'wiki_topic_end_bound_7.csv', 'wiki_topic_end_unbound_7.csv', 'wiki_topic_mid_bound_7.csv', 'wiki_topic_mid_unbound_7.csv']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import statistics\n",
    "file_path = \"AES_testcases/prompt7/\"\n",
    "files = os.listdir(file_path)\n",
    "files = sorted(files)\n",
    "files.pop(0)\n",
    "\n",
    "print(len(files), files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.855\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bf311155cab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEssaySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messaytype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_essaylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_essay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_essaylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scorelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     print(\"features test\", Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/ease/ease/essay_set.py\u001b[0m in \u001b[0;36madd_essay\u001b[0;34m(self, essay_text, essay_score, essay_generated)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m#print(\"CT3\", self._clean_text[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m#print(len(self._pos), self._pos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m    161\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Maps to the specified tagset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eng'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mprev2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Do a secondary alphabetic sort, for stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import os \n",
    "# import statistics\n",
    "# file_path = \"AES_testcases/prompt1/\"\n",
    "# files = os.listdir(file_path)\n",
    "# print(files)\n",
    "for testcase in files:\n",
    "#     print(testcase)\n",
    "    test_set = pd.read_csv(file_path+testcase, encoding=\"latin1\")\n",
    "    x = test_set.to_numpy()\n",
    "    tester = x.tolist()\n",
    "    test_essaylist = []\n",
    "\n",
    "    for i in range(0, len(tester)):\n",
    "        z = tester[i]\n",
    "#         print(z)\n",
    "        y = z[0].split(', ', 1)\n",
    "        test_essaylist.append(y[0])\n",
    "\n",
    "    test = EssaySet(essaytype=\"test\")\n",
    "    for i in range(0, len(test_essaylist)):\n",
    "        test.add_essay(test_essaylist[i], test_scorelist[i])\n",
    "    Y = features.gen_feats(test)\n",
    "#     print(\"features test\", Y)\n",
    "#     print(\"Done4\")\n",
    "\n",
    "    ## SCALING\n",
    "    scaled_train = []\n",
    "    for i in range(0, len(scorelist)):\n",
    "        scaled_train.append(float((np.clip((scorelist[i]), a_min=0, a_max=30)/30)))\n",
    "\n",
    "#     print(\"start training and prediciton\")\n",
    "\n",
    "    # print(scaled_train)\n",
    "    from sklearn.svm import SVR\n",
    "\n",
    "    # Values for prompt1\n",
    "    Cs = [100]\n",
    "    gammas = [0.000001]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    clf = GridSearchCV(SVR(kernel='rbf'), param_grid, cv =5)\n",
    "    clf.fit(X, scaled_train)\n",
    "#     print(clf.best_params_)\n",
    "\n",
    "    final = clf.predict(Y)\n",
    "\n",
    "    finals = np.rint(np.clip(final,a_min=0,a_max=1)*30)\n",
    "    finals_list = finals.tolist()\n",
    "#     mean_diff = statistics.mean(finals_list)\n",
    "#     print(\"Mean\", statistics.mean(diff_list))\n",
    "#     print(\"\"+\"{:.3f}\".format(mean_diff))\n",
    "    diff_list =[]\n",
    "    for i in range(0, len(finals_list)):\n",
    "    #     print(finals_list[i], test_scorelist[i])\n",
    "        diff = test_scorelist[i] - finals_list[i]\n",
    "        diff_list.append(diff)\n",
    "#     print(\"\", statistics.mean(diff_list))\n",
    "    mean1 = statistics.mean(diff_list)\n",
    "    print(\"\"+\"{:.3f}\".format(mean1))\n",
    "    \n",
    "    \n",
    "#     diff_list =[]\n",
    "#     for i in range(0, len(finals_list)):\n",
    "#     #     print(finals_list[i], test_scorelist[i])\n",
    "#         diff = test_scorelist[i] - finals_list[i]\n",
    "#         diff_list.append(diff)\n",
    "#     mean_diff = statistics.mean(diff_list)\n",
    "# #     print(\"Mean\", statistics.mean(diff_list))\n",
    "#     print(\"\"+\"{:.3f}\".format(mean_diff))\n",
    "#         # print(len(finals_list), len(test_scorelist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28583632 0.29144578 0.29469176 0.3010146  0.29678894 0.27565501\n",
      " 0.29401789 0.29813644 0.27248337 0.28798591 0.2515703  0.29745256\n",
      " 0.29813644 0.29678894 0.29546236 0.28513957 0.25656519 0.29545356\n",
      " 0.29813644 0.29546236 0.24918369 0.28227529 0.29813644 0.26942308\n",
      " 0.2554716  0.29545356 0.29144578 0.250061   0.29677625 0.25821334\n",
      " 0.29545356 0.29745256 0.29545356 0.2800879  0.29144578 0.29745256\n",
      " 0.29020527 0.29545356 0.28750589 0.29469176 0.29813644 0.29262794\n",
      " 0.29813644 0.29813644 0.29532778 0.28821227 0.2514389  0.29545356\n",
      " 0.24887221 0.29545356 0.29144578 0.29813644 0.29323807 0.27718626\n",
      " 0.29144578 0.29599281 0.25790319 0.29813644 0.29286886 0.29813644\n",
      " 0.2500658  0.29745256 0.29535372 0.29813644 0.29469176 0.26363276\n",
      " 0.29545356 0.29144578 0.29144578 0.28897303 0.33530783 0.60255487\n",
      " 0.25303503 0.28787152 0.29813644 0.2908179  0.27687227 0.2946723\n",
      " 0.29469176 0.29469176 0.29813644 0.29144578 0.28631821 0.29469176\n",
      " 0.29145309 0.28062391 0.24882527 0.29894694 0.29745256 0.26119265\n",
      " 0.29545356 0.29286886 0.29144578 0.3010146  0.26120963 0.29677625\n",
      " 0.27051042 0.28643966 0.29545356 0.25160966 0.29813644 0.26721667\n",
      " 0.34943201 0.28948775 0.29144578 0.29545356 0.29813644 0.29745256\n",
      " 0.29469176 0.29144578 0.29745256 0.28763214 0.25512329 0.29813644\n",
      " 0.29469176 0.29745166 0.29813644 0.27139129 0.28525339 0.29813644\n",
      " 0.28871044 0.24980582 0.29144578 0.27994984 0.60179837 0.29678894\n",
      " 0.29286886 0.26843481 0.29745256 0.58299584 0.29144578 0.24874952\n",
      " 0.29469176 0.24933011 0.28958541 0.29144578 0.25023002 0.29532338\n",
      " 0.29813644 0.29469176 0.28959275 0.29144578 0.29144578 0.24937327\n",
      " 0.29545356 0.29813644 0.29144578 0.29469176 0.2490307  0.2491101\n",
      " 0.29545356 0.26299617 0.29138292 0.29813644 0.26168778 0.29146022\n",
      " 0.29144578 0.29444177 0.29813644 0.29813644 0.29545356 0.29286886\n",
      " 0.29469176 0.29145309 0.29144578 0.27658023 0.29144578 0.25572823\n",
      " 0.29745256 0.29144578 0.29144578 0.29469176 0.29144578 0.25170327\n",
      " 0.29894694 0.27533151 0.28871779 0.29208609 0.29144578 0.29144578\n",
      " 0.29545356 0.29813644 0.29466169 0.24998933 0.24876591 0.29144578\n",
      " 0.31938344 0.29796299 0.2781135  0.25105093 0.29813644 0.29677625\n",
      " 0.28761839 0.29813644 0.29144578 0.29071454 0.29745256 0.29745256\n",
      " 0.29545356 0.29144578 0.31052745 0.26157243 0.30179398 0.28750514\n",
      " 0.24874748 0.30113782 0.27811875 0.29144578 0.35315904 0.27050208\n",
      " 0.25793107 0.25846379 0.66894142 0.29144578 0.29678894 0.29813644\n",
      " 0.29144578 0.26577187 0.29545356 0.31160378 0.24959661 0.24915333\n",
      " 0.29081669 0.29466169 0.29813644 0.29677625 0.29144578 0.29677625\n",
      " 0.29144578 0.29677625 0.25609242 0.29532778 0.25376233 0.29545356\n",
      " 0.2760647  0.2607875  0.29144578 0.29677625 0.29401566 0.29532778\n",
      " 0.29545356 0.29813644 0.29286886 0.6951517  0.29894694 0.29145309\n",
      " 0.28387953 0.30768125 0.28748593 0.29677625 0.29532778 0.27028164\n",
      " 0.29545356 0.27195503 0.29144578 0.29145309 0.53194805 0.24882634\n",
      " 0.29532778 0.27091585 0.35442915 0.24883649 0.29813644 0.25830328\n",
      " 0.25760742 0.29598786 0.29813644 0.29144578 0.29469176 0.29677625\n",
      " 0.29286886 0.29144578 0.24906408 0.29144578 0.28403527 0.28203563\n",
      " 0.29144578 0.29532978 0.29144578 0.29068424 0.29144578 0.29390144\n",
      " 0.29144578 0.29677625 0.29532778 0.55965041 0.26961771 0.29144578\n",
      " 0.28958663 0.29144578 0.74030506 0.68990197 0.51727185 0.25165766\n",
      " 0.29469176 0.25034561 0.29813644 0.29745256 0.47986961 0.27092995\n",
      " 0.29259605 0.29144578 0.28516192 0.29071454 0.29813644 0.29813644\n",
      " 0.29286886 0.29286886 0.29545356 0.28029312 0.61553146 0.29144578\n",
      " 0.29144578 0.29144578 0.26122979 0.29209503 0.25466692 0.59732075\n",
      " 0.25276276 0.29678107 0.29144578 0.29545356 0.282714   0.28136765\n",
      " 0.29678894 0.25903309 0.35781127 0.29144578 0.29144578 0.54588166\n",
      " 0.29545356 0.55174967 0.29677625 0.2908179  0.29545356 0.29813644\n",
      " 0.29081669 0.29144578 0.29387678 0.29145309 0.2595985  0.29469176\n",
      " 0.28701169 0.29145309 0.29144578 0.25458052 0.29677625 0.53301435\n",
      " 0.33757388 0.38720119 0.29545356 0.282714   0.26105759 0.28749045\n",
      " 0.48337715 0.29258649 0.25641345]\n",
      "Mean 4.829131652661064\n"
     ]
    }
   ],
   "source": [
    "print(final)\n",
    "import statistics\n",
    "\n",
    "diff_list =[]\n",
    "for i in range(0, len(finals_list)):\n",
    "#     print(finals_list[i], test_scorelist[i])\n",
    "    diff = test_scorelist[i] - finals_list[i]\n",
    "    diff_list.append(diff)\n",
    "print(\"Mean\", statistics.mean(diff_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
